import re
import ast
import string
from typing import Optional
from pathlib import Path

import hishel
import numpy as np
import pandas as pd
import networkx as nx


def softmax(input_arr: np.ndarray, temperature: float) -> np.ndarray:
    return np.exp(input_arr / temperature) / np.exp(input_arr / temperature).sum()


def compute_edit_distance(
    graph: nx.Graph, p_graph: nx.Graph, node_id_field: str, edge_id_field: str
) -> float:
    def _node_match(n1: dict, n2: dict) -> bool:
        return n1[node_id_field] == n2[node_id_field]

    def _edge_match(e1: dict, e2: dict) -> bool:
        return e1[edge_id_field] == e2[edge_id_field]

    return nx.graph_edit_distance(
        graph,
        p_graph,
        node_match=_node_match,
        edge_match=_edge_match,
    )


def find_field_placeholders(text: str) -> list[str]:
    """Finds field placeholders in unformatted strings.

    NOTE: double brackets don't work.
    """
    placeholders = [item[1] for item in string.Formatter().parse(text) if item[1]]
    return placeholders


def get_hishel_http_client(cache_dir: Optional[str | Path] = None):
    """Wraps an HTTP client to enable caching"""
    if isinstance(cache_dir, str):
        cache_dir = Path(cache_dir)

    controller = hishel.Controller(force_cache=True, cacheable_methods=["GET", "POST"])
    storage = hishel.FileStorage(base_path=cache_dir)
    http_client = hishel.CacheClient(controller=controller, storage=storage)

    return http_client


def load_subgraph_dataset(fpath: Path | str) -> pd.DataFrame:
    subgraph_dataset = pd.read_csv(str(fpath))

    transform_cols = [
        "subgraph_triples",
        "perturbed_subgraph_triples",
        "perturbation_log",
    ]
    for col in transform_cols:
        # Removes any np.str_ formatted strings
        subgraph_dataset[col] = subgraph_dataset[col].apply(
            lambda x: re.sub(r"np\.str_\(\'(.+?)\'\)", r"'\1'", x)
        )
        subgraph_dataset[col] = subgraph_dataset[col].apply(ast.literal_eval)

    return subgraph_dataset


def create_edge_map(
    triple_df: pd.DataFrame,
    src_node_type_field: str,
    target_node_type_field: str,
    edge_name_field: str,
    directed: bool = True,
) -> dict[tuple[str, str], list[str]]:
    """Creates a map of node-types to edge-types

    Uses the existing dataset to characterise what types of edge-types
    are shared between different node-types. Can be used for defining
    acceptable edge-replacements

    Returns
    -------
    dict[tuple[str, str], list[str]]
        A dictionary denoting each node-type pair and all corresponding
        edge-types
    """
    triple_df["node_types"] = list(
        triple_df[[src_node_type_field, target_node_type_field]].itertuples(
            index=False, name=None
        )
    )
    if not directed:
        triple_df["node_types"] = triple_df["node_types"].apply(
            lambda x: tuple(sorted(x))
        )
    return (
        triple_df[["node_types", edge_name_field]]
        .groupby("node_types")
        .agg(lambda x: list(x.unique()))[edge_name_field]
        .to_dict()
    )


def create_replace_map(
    edge_map: dict[tuple[str, str], list[str]],
) -> dict[str, list[str]]:
    """Creates a `replace_map` from an `edge_map`

    Helper function will automatically generate a `replace_map`
    used by `SubgraphPipeline` using `edge_map` (generated by
    `create_edge_map`)

    NOTE: This function is not recommended as some suggested replacements
    may be synonyms of a given relation. Manually specifying is preferred

    Parameters
    ----------
    edge_map : dict[tuple[str, str], list[str]]
        A map from node-types to edge-names (generated by
        `semantic_kg.utils.create_edge_map`)

    Returns
    -------
    dict[str, list[str]]
        A map from a relation name to allowed replacements
    """
    edge_map = {k: v for k, v in edge_map.items() if len(v) > 1}
    replace_map = {}
    for relations in edge_map.values():
        for relation in relations:
            allowed_replacements = [r for r in relations if r != relation]
            if len(allowed_replacements) > 0:
                replace_map[relation] = allowed_replacements

    return replace_map


def get_start_nodes_from_replace_map(
    replace_map: dict[str, list[str]],
    triple_df: pd.DataFrame,
    edge_name_field: str,
    attr_field: str,
) -> list[str]:
    """Retrieves nodes with valid replacement values based on `replace_map`

    Helper function to retrieve start nodes with known replacement values to
    increase the likelihood of sampling a subgraph with a valid edge-replacement.
    Useful for KGs where only a few edge-types have accepted replacements.

    Parameters
    ----------
    replace_map : dict[str, list[str]]
        A node replace map generated by `semantic_kg.utils.create_replace_map`
    triple_df : pd.DataFrame
        Triple dataframe
    edge_name_field : str
        Name of field in dataframe containing edge-names
    attr_field : str
        Node attribute field to return. For example "src_node_name" if wanting
        to retrieve the name of every source node with a valid replacement value.
        Or "src_node_type" if just wanting to retrieve a list of node-types.

    Returns
    -------
    list[str]
        List of node-attributes with valid replacement values.
    """
    replace_vals = list(replace_map.keys())
    return (
        triple_df[triple_df[edge_name_field].isin(replace_vals)][attr_field]
        .unique()
        .tolist()
    )
